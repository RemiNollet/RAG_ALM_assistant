{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fda3cc-0e34-4695-b024-691170b1d656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval data link: https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/447dd4/dataset_eval.zip\n",
    "!curl -L -o ../data/dataset_eval.zip https://blent-learning-user-ressources.s3.eu-west-3.amazonaws.com/projects/447dd4/dataset_eval.zip\n",
    "!unzip -d ../data/eval ../data/dataset_eval.zip\n",
    "!rm ../data/dataset_eval.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1bd144-e8a7-4b6d-80bc-b7bdec5b0d0f",
   "metadata": {},
   "source": [
    "# Create database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa79d5-494d-4b2d-8ab4-bb2857617b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from rag_alm_assistant.ingestion import full_ingestion_pipeline\n",
    "from rag_alm_assistant.constants import DIC_DIR, VECTORSTORE_DIR, EMBEDDING_MODEL_NAME\n",
    "\n",
    "vector_store, raw_docs, chunks = full_ingestion_pipeline(\n",
    "    dic_dir=\"../data/DIC\",\n",
    "    persist_directory=\"../data/vector_store\",\n",
    "    model_name=EMBEDDING_MODEL_NAME,\n",
    ")\n",
    "\n",
    "print(\"Nb docs bruts :\", len(raw_docs))\n",
    "print(\"Nb chunks     :\", len(chunks))\n",
    "print(\"Vector store  :\", VECTORSTORE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e151df8-f571-4e4d-aa17-31e15adf5d5a",
   "metadata": {},
   "source": [
    "# Health check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525516c4-deca-4bc9-9b1f-452eeb84417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how ert score works\n",
    "from bert_score import score\n",
    "\n",
    "# 1) même phrase => score proche de 1\n",
    "refs = [\"L’OPCVM est un fonds d’investissement collectif en valeurs mobilières.\"]\n",
    "preds = [\"L’OPCVM est un fonds d’investissement collectif en valeurs mobilières.\"]\n",
    "\n",
    "P, R, F1 = score(preds, refs, lang=\"fr\")\n",
    "print(\"Identiques F1:\", F1.mean().item())\n",
    "\n",
    "# 2) phrases proches => score élevé\n",
    "refs2 = [\"L’OPCVM permet un investissement collectif sur les marchés financiers.\"]\n",
    "preds2 = [\"Un OPCVM est un produit qui permet d’investir collectivement en titres financiers.\"]\n",
    "\n",
    "P2, R2, F12 = score(preds2, refs2, lang=\"fr\", rescale_with_baseline=True)\n",
    "print(\"Semblables F1:\", F12.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384eb70c-459a-43dc-9d05-0b9a16193db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check few samples of answers:\n",
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from rag_alm_assistant.orchestrator import RAGOrchestrator\n",
    "import random\n",
    "from bert_score import score\n",
    "\n",
    "EVAL_DIR = Path(\"../data/eval\")\n",
    "with open(EVAL_DIR / \"queries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries = json.load(f)\n",
    "with open(EVAL_DIR / \"answers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_answers = json.load(f)\n",
    "\n",
    "orchestrator = RAGOrchestrator(use_reranker = True, use_memory= False, k_rerank = 5, k = 10)\n",
    "\n",
    "sample_uuids = random.sample(list(queries.keys()), 20)\n",
    "preds = []  # answer from our pipeline\n",
    "refs = []   # references\n",
    "\n",
    "for uid in sample_uuids:\n",
    "    q = queries[uid]\n",
    "    ref_answer = gold_answers[uid]\n",
    "    pred_answer, pred_sources = orchestrator.ask(q)\n",
    "    preds.append(pred_answer)\n",
    "    refs.append(ref_answer)\n",
    "\n",
    "    print(\"==== UID:\", uid, \"====\")\n",
    "    print(\"Question :\", q)\n",
    "    print(\"\\nGold answer :\\n\", ref_answer)\n",
    "    print(\"\\nPred answer :\\n\", pred_answer)\n",
    "    print(\"\\nSources prédictes :\", pred_sources)\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Calcul BERTScore\n",
    "P, R, F1 = score(\n",
    "    cands=preds,\n",
    "    refs=refs,\n",
    "    lang=\"fr\"\n",
    ")\n",
    "\n",
    "f1_mean = F1.mean().item()\n",
    "print(f\"Mean BERTScore F1: {f1_mean:.4f}  ({f1_mean*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbef22a-decc-4576-a1cc-973ace247c93",
   "metadata": {},
   "source": [
    "# Evaluation without reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca20371-2875-4991-8213-c07201796ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from rag_alm_assistant.orchestrator import RAGOrchestrator\n",
    "\n",
    "from bert_score import score\n",
    "\n",
    "EVAL_DIR = Path(\"../data/eval\")\n",
    "\n",
    "with open(EVAL_DIR / \"queries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "with open(EVAL_DIR / \"answers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_answers = json.load(f)\n",
    "\n",
    "with open(EVAL_DIR / \"relevant_docs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_sources = json.load(f)\n",
    "\n",
    "uuids = list(queries.keys())\n",
    "orchestrator = RAGOrchestrator(use_reranker = False, use_memory= False)\n",
    "\n",
    "preds = []  # answer from our pipeline\n",
    "refs = []   # references\n",
    "\n",
    "for uid in uuids:\n",
    "    q = queries[uid]\n",
    "    ref_answer = gold_answers[uid]\n",
    "    ref_sources = gold_sources[uid]\n",
    "\n",
    "    pred_answer, pred_source = orchestrator.ask(q)\n",
    "    # print(\"\\nSources prédictes :\", pred_source)\n",
    "\n",
    "    preds.append(pred_answer)\n",
    "    refs.append(ref_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdaaa44-5c2e-4c89-99ca-568ab1d9ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul BERTScore\n",
    "P, R, F1 = score(\n",
    "    cands=preds,\n",
    "    refs=refs,\n",
    "    lang = \"fr\",\n",
    "    rescale_with_baseline=True\n",
    ")\n",
    "\n",
    "f1_mean = F1.mean().item()\n",
    "print(f\"Mean BERTScore F1: {f1_mean:.4f}  ({f1_mean*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a32925-9ebe-44f3-a0af-d3562e9162ad",
   "metadata": {},
   "source": [
    "# Evaluation with reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad3810-1ee7-4d2f-a916-c4e0801a685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from rag_alm_assistant.orchestrator import RAGOrchestrator\n",
    "\n",
    "from bert_score import score\n",
    "\n",
    "EVAL_DIR = Path(\"../data/eval\")\n",
    "\n",
    "with open(EVAL_DIR / \"queries.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    queries = json.load(f)\n",
    "\n",
    "with open(EVAL_DIR / \"answers.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_answers = json.load(f)\n",
    "\n",
    "with open(EVAL_DIR / \"relevant_docs.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    gold_sources = json.load(f)\n",
    "\n",
    "uuids = list(queries.keys())\n",
    "orchestrator = RAGOrchestrator(use_reranker = True, use_memory=False, k_rerank = 5, k = 10)\n",
    "\n",
    "preds = []  # answer from our pipeline\n",
    "refs = []   # references\n",
    "\n",
    "for uid in uuids:\n",
    "    q = queries[uid]\n",
    "    ref_answer = gold_answers[uid]\n",
    "    ref_sources = gold_sources[uid]\n",
    "\n",
    "    pred_answer, pred_source = orchestrator.ask(q)\n",
    "\n",
    "    preds.append(pred_answer)\n",
    "    refs.append(ref_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88f37dd2-2846-4149-a995-4c16cc97ea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean BERTScore F1: 0.7957  (79.57%)\n"
     ]
    }
   ],
   "source": [
    "# Calcul BERTScore\n",
    "P, R, F1 = score(\n",
    "    cands=preds,\n",
    "    refs=refs,\n",
    "    lang = \"fr\"\n",
    ")\n",
    "\n",
    "f1_mean = F1.mean().item()\n",
    "print(f\"Mean BERTScore F1: {f1_mean:.4f}  ({f1_mean*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017155a6-b2fe-4be5-8c23-8e08c613e005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ca9f5b-19a2-4227-99c1-3b9ffaaad3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
